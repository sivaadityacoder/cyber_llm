#!/bin/bash

# Enhanced OwnLLM Startup Script v3.0
# Starts the comprehensive ethical hacking and LLM security AI assistant

echo "ðŸ›¡ï¸ Starting Enhanced Ethical Hacking LLM v3.0..."
echo "ðŸ”’ Features: Cybersecurity + LLM Security + AI Safety"
echo "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "="

cd /home/coder/startup/ownllm

# Check if virtual environment exists
if [ ! -d "venv" ]; then
    echo "âŒ Virtual environment not found. Creating..."
    python3 -m venv venv
    source venv/bin/activate
    pip install -r Backend/requirements.txt
    pip install -r Frontend/requirements.txt
else
    echo "âœ… Virtual environment found"
fi

# Kill any existing processes
echo "ðŸ§¹ Cleaning up existing processes..."
pkill -f "main_enhanced" 2>/dev/null
pkill -f "streamlit.*enhanced" 2>/dev/null
sleep 2

# Start backend
echo "ðŸš€ Starting Enhanced Backend (Port 8000)..."
source venv/bin/activate
python3 Backend/main_enhanced.py &
BACKEND_PID=$!

# Wait for backend to start
echo "â³ Waiting for backend to initialize..."
sleep 5

# Check if backend is running
if curl -s http://localhost:8000/health > /dev/null; then
    echo "âœ… Backend started successfully"
    
    # Get model info
    MODEL_INFO=$(curl -s http://localhost:8000/model/info | python3 -c "
import sys, json
data = json.load(sys.stdin)
print(f'Model: {data[\"model_name\"]}')
print(f'Training Examples: {data[\"training_examples\"]}')
print(f'LLM Security Features: {len(data[\"llm_security_coverage\"])}')
" 2>/dev/null)
    
    if [ $? -eq 0 ]; then
        echo "ðŸ“Š $MODEL_INFO"
    fi
else
    echo "âŒ Backend failed to start"
    kill $BACKEND_PID 2>/dev/null
    exit 1
fi

# Start frontend
echo "ðŸŽ¨ Starting Enhanced Frontend (Port 8501)..."
streamlit run Frontend/streamlit_app_enhanced.py --server.port 8501 --server.address 0.0.0.0 &
FRONTEND_PID=$!

# Wait for frontend to start
echo "â³ Waiting for frontend to initialize..."
sleep 8

# Check if frontend is running
if curl -s -I http://localhost:8501 > /dev/null; then
    echo "âœ… Frontend started successfully"
else
    echo "âŒ Frontend failed to start"
    kill $BACKEND_PID $FRONTEND_PID 2>/dev/null
    exit 1
fi

echo ""
echo "ðŸŽ‰ Enhanced Ethical Hacking LLM v3.0 is now running!"
echo "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "="
echo "ðŸŒ Frontend UI:      http://localhost:8501"
echo "ðŸ”Œ Backend API:      http://localhost:8000"
echo "ðŸ“š API Documentation: http://localhost:8000/docs"
echo ""
echo "ðŸ›¡ï¸ Security Features Available:"
echo "  â€¢ Traditional Cybersecurity (Web, Network, System)"
echo "  â€¢ LLM Security (Prompt Injection, Jailbreaking)" 
echo "  â€¢ AI Safety (Secure Deployment, Testing)"
echo "  â€¢ 46 Comprehensive Training Examples"
echo "  â€¢ 12 Security Domain Coverage"
echo ""
echo "ðŸ’¡ Try asking about:"
echo "  â€¢ 'What is prompt injection and how to prevent it?'"
echo "  â€¢ 'Explain SQL injection attacks'"
echo "  â€¢ 'How do LLM jailbreaking techniques work?'"
echo ""
echo "ðŸ›‘ To stop: ./stop.sh or Ctrl+C in terminals"
echo "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "="

# Save PIDs for stop script
echo $BACKEND_PID > .backend_pid
echo $FRONTEND_PID > .frontend_pid

# Wait for user interrupt
wait

# Cyber LLM Framework Configuration

security:
  max_input_length: 10000
  max_output_length: 5000
  rate_limit_requests: 100
  rate_limit_window: 3600
  sanitization_level: "moderate"
  enable_monitoring: true
  log_level: "INFO"

api:
  host: "0.0.0.0"
  port: 8000
  debug: false
  cors_origins:
    - "http://localhost:3000"
    - "http://localhost:8080"
  api_key_required: true

llm:
  default_provider: "openai"
  default_model: "gpt-3.5-turbo"
  max_tokens: 1000
  temperature: 0.7
  timeout: 30

monitoring:
  prometheus_port: 9090
  enable_metrics: true
  log_file: "/var/log/cyber_llm.log"
# Cyber LLM Framework Environment Configuration
# Copy this file to .env and customize as needed

# Security Settings
CYBER_LLM_MAX_INPUT_LENGTH=10000
CYBER_LLM_MAX_OUTPUT_LENGTH=5000
CYBER_LLM_RATE_LIMIT_REQUESTS=100
CYBER_LLM_RATE_LIMIT_WINDOW=3600
CYBER_LLM_SANITIZATION_LEVEL=moderate
CYBER_LLM_ENABLE_MONITORING=true
CYBER_LLM_LOG_LEVEL=INFO

# API Settings
CYBER_LLM_HOST=0.0.0.0
CYBER_LLM_PORT=8000
CYBER_LLM_DEBUG=false
CYBER_LLM_API_KEY_REQUIRED=true
CYBER_LLM_CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# LLM Provider Settings
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
CYBER_LLM_DEFAULT_PROVIDER=openai
CYBER_LLM_DEFAULT_MODEL=gpt-3.5-turbo
CYBER_LLM_MAX_TOKENS=1000
CYBER_LLM_TEMPERATURE=0.7
CYBER_LLM_TIMEOUT=30

# Monitoring and Logging
CYBER_LLM_PROMETHEUS_PORT=9090
CYBER_LLM_LOG_FILE=/var/log/cyber_llm.log
CYBER_LLM_ENABLE_METRICS=true